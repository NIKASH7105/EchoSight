Sure thing. Hereâ€™s your **EchoSight README styled with GitHub-friendly icons, emojis, clean formatting, and better visual hierarchy** â€” perfect for a polished repository.

---

# âœ¨ **EchoSight â€“ Real-Time Vision-to-Voice Assistant**

> ğŸ”Š *See the world through sound.*

EchoSight is a modular, offline, real-time **vision-to-audio assistive toolkit** designed for visually impaired users.
It integrates **YOLO object detection**, **traffic-light color classification**, **OCR text reading**, and **offline speech output** into one seamless system.

Runs on laptops, desktops, and even **Raspberry Pi** with lightweight models.

---

## ğŸ“¦ **Repository Contents**

This project includes multiple coordinated subsystems:

ğŸ“Œ **Main unified system**

* `unified_echosight_system.py`
  *Full pipeline: YOLO + OCR + traffic-light color + voice feedback*

ğŸ“Œ **Object detection** (`object_detection/`)

* `obj_detect.py` â€“ YOLO helper utilities
* `single_cam_live_system.py` â€“ live camera detection
* `unified_vision_system.py` â€“ multi-function pipeline

ğŸ“Œ **Traffic-light processing** (`traffic_signal/`)

* `cnn_model.py` â€“ CNN classifier (Red/Yellow/Green)
* `traffic_color_system.py` â€“ real-time color prediction + voice

ğŸ“Œ **OCR system** (`OCR/`)

* `ocr_main.py` â€“ OCR pipeline
* `CRAFT/` â€“ text-detection models & weights

ğŸ“Œ **Voice/TTS system** (`voice/`)

* `voice_engine.py` â€“ Offline speech (pyttsx3 / Coqui)

ğŸ“Œ **Tests**

* `test_voice_system.py`
* `test_ocr_integration.py`
* `test_full_pipeline.py`

ğŸ“Œ **Models**

* `yolov8n.pt` â€“ small YOLO model
* `traffic_cnn.pth` â€“ traffic-light classifier
* `craft_mlt_25k.pth` â€“ OCR detector weights

---

## ğŸš€ **Quickstart (Windows PowerShell)**

### âœ… 1. Create & activate virtual environment

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### âœ… 2. Install requirements

```powershell
pip install -r requirements.txt
```

### âœ… 3. Run the full EchoSight system

```powershell
python unified_echosight_system.py
```

---

## ğŸ” **Run Individual Modules**

### â–¶ Object Detection Only

```powershell
python object_detection\unified_vision_live_system.py
```

### ğŸš¦ Traffic-Light Color Recognition

```powershell
python trafficli\working_voice_system.py
```

### ğŸ“– OCR Reader

```powershell
python OCR\working_ocr_pipeline.py
```

### ğŸ”Š Voice/TTS Test

```powershell
python test_voice_system.py
```

### ğŸ§ª Tests

```powershell
python test_voice_system.py
python test_ocr_integration.py
python test_full_pipeline.py
```

---

## ğŸ“ **Important Entrypoints**

| Module                           | Description                      |
| -------------------------------- | -------------------------------- |
| `unified_echosight_system.py`    | ğŸ”¥ Full Vision-to-Voice Pipeline |
| `object_detection/obj_detect.py` | ğŸ§  YOLO detection utilities      |
| `traffic_signal/cnn_model.py`    | ğŸš¦ Traffic-light classifier      |
| `OCR/ocr_main.py`                | ğŸ“š OCR text reader               |
| `voice/voice_engine.py`          | ğŸ”Š Offline TTS engine            |

---

## ğŸ§  **Models Used**

| Model               | Purpose                            |
| ------------------- | ---------------------------------- |
| `yolov8n.pt`        | Real-time object detection         |
| `traffic_cnn.pth`   | Traffic-light color classification |
| `craft_mlt_25k.pth` | OCR text detector                  |

Paths can be customized inside the script or passed as CLI parameters.

---

## ğŸ› ï¸ **Development Notes**

* The system is fully modular â€” you can use only detection, only OCR, or combine everything.
* For a lean deployment, keep only:

  * `unified_echosight_system.py`
  * `object_detection/obj_detect.py`
  * `traffic_signal/traffic_color_system.py`
  * `OCR/ocr_main.py`
  * `voice/voice_engine.py`
  * `models/`

---